{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9338078,"sourceType":"datasetVersion","datasetId":5658771}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\nfrom datasets import load_dataset\n\n# Load the M2M100 model and tokenizer\nmodel_name = \"facebook/m2m100_418M\"\nmodel = M2M100ForConditionalGeneration.from_pretrained(model_name)\ntokenizer = M2M100Tokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:00:12.633447Z","iopub.execute_input":"2024-09-07T10:00:12.633743Z","iopub.status.idle":"2024-09-07T10:00:45.920238Z","shell.execute_reply.started":"2024-09-07T10:00:12.633710Z","shell.execute_reply":"2024-09-07T10:00:45.919313Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/908 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1c53161e43d4d74aa4791505bab4aa7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3500ed8c311145669031b2afa9d8cf47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/233 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db9f8d60beea4670a76db0cba4465bfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/298 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"101f95d29d4a4931b550f03931089c98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/3.71M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f96d94bc24314921997302d33151083a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87253f43f09146a4b03cb9ee8a25e67f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5053d26ad9f94a2781eda6293d3c4f92"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\n\ndf = pd.read_csv('/kaggle/input/mansi-mono/mansi.csv', index_col=0)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:00:45.922010Z","iopub.execute_input":"2024-09-07T10:00:45.922725Z","iopub.status.idle":"2024-09-07T10:00:46.814193Z","shell.execute_reply.started":"2024-09-07T10:00:45.922684Z","shell.execute_reply":"2024-09-07T10:00:46.813342Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_df, test_val_df = train_test_split(df, test_size=0.2, random_state=42)\nval_df, test_df = train_test_split(test_val_df, test_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:00:46.815346Z","iopub.execute_input":"2024-09-07T10:00:46.815652Z","iopub.status.idle":"2024-09-07T10:00:48.007595Z","shell.execute_reply.started":"2024-09-07T10:00:46.815620Z","shell.execute_reply":"2024-09-07T10:00:48.006436Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:00:48.010248Z","iopub.execute_input":"2024-09-07T10:00:48.010651Z","iopub.status.idle":"2024-09-07T10:00:48.483190Z","shell.execute_reply.started":"2024-09-07T10:00:48.010606Z","shell.execute_reply":"2024-09-07T10:00:48.482078Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:00:48.484982Z","iopub.execute_input":"2024-09-07T10:00:48.485487Z","iopub.status.idle":"2024-09-07T10:00:48.495877Z","shell.execute_reply.started":"2024-09-07T10:00:48.485437Z","shell.execute_reply":"2024-09-07T10:00:48.494331Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['0', '__index_level_0__'],\n    num_rows: 146499\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.add_special_tokens({'mask_token': '[MASK]'})\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-09-07T13:28:50.970673Z","iopub.execute_input":"2024-09-07T13:28:50.971173Z","iopub.status.idle":"2024-09-07T13:28:51.335219Z","shell.execute_reply.started":"2024-09-07T13:28:50.971130Z","shell.execute_reply":"2024-09-07T13:28:51.334257Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"M2M100ScaledWordEmbedding(128105, 1024, padding_idx=1)"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = tokenizer(examples['0'], return_special_tokens_mask=True, truncation=True, padding=\"max_length\", max_length=128)\n    return inputs\n\ntrain_dataset = train_dataset.map(preprocess_function, batched=True)\nval_dataset = val_dataset.map(preprocess_function, batched=True)\ntest_dataset = test_dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:00:52.269399Z","iopub.execute_input":"2024-09-07T10:00:52.269835Z","iopub.status.idle":"2024-09-07T10:02:01.368297Z","shell.execute_reply.started":"2024-09-07T10:00:52.269796Z","shell.execute_reply":"2024-09-07T10:02:01.367221Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/146499 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23577aff69ca40ef8efaadbf829ff24e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/18312 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edc346bee21b40ab905ef49a4f14642b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/18313 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d965c1c1cac4eb78ba00571a9ec508e"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = train_dataset.remove_columns(['__index_level_0__', '0'])\nval_dataset = val_dataset.remove_columns(['__index_level_0__', '0'])\ntest_dataset = test_dataset.remove_columns(['__index_level_0__', '0'])","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:02:01.369895Z","iopub.execute_input":"2024-09-07T10:02:01.370355Z","iopub.status.idle":"2024-09-07T10:02:01.382890Z","shell.execute_reply.started":"2024-09-07T10:02:01.370303Z","shell.execute_reply":"2024-09-07T10:02:01.381909Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Data collator for MLM - this automatically masks some tokens in the input\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, \n    mlm=True,  # Set to True to enable masked language modeling\n    mlm_probability=0.2  # Mask 20% of tokens\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T13:29:08.556461Z","iopub.execute_input":"2024-09-07T13:29:08.557299Z","iopub.status.idle":"2024-09-07T13:29:08.561729Z","shell.execute_reply.started":"2024-09-07T13:29:08.557256Z","shell.execute_reply":"2024-09-07T13:29:08.560767Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Training Arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./m2m_smugri_finetuned\",\n    evaluation_strategy=\"no\", \n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=2, \n    weight_decay=0.01,\n    save_strategy=\"epoch\", \n    num_train_epochs=1,\n#     max_steps=41202,\n    logging_dir=\"./logs\",\n    report_to=\"none\", \n    fp16=True, \n    load_best_model_at_end=False,                    \n)\n\n# Trainer setup\ntrainer = Trainer(\n    model=model,                         # The M2M100 model\n    args=training_args,                  # Training arguments\n    data_collator=data_collator,         # Data collator for MLM\n    train_dataset=train_dataset,         # Training dataset\n    eval_dataset=test_dataset\n)\n\n# Train the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-07T13:36:33.302351Z","iopub.execute_input":"2024-09-07T13:36:33.303352Z","iopub.status.idle":"2024-09-07T16:29:42.579713Z","shell.execute_reply.started":"2024-09-07T13:36:33.303307Z","shell.execute_reply":"2024-09-07T16:29:42.578800Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='9156' max='9156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [9156/9156 2:53:07, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.307600</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.625800</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.477300</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.443000</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.348700</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.306100</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>1.242100</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.225900</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.174400</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.152300</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>1.183000</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.131800</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>1.160000</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>1.143500</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>1.145900</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>1.176000</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>1.163500</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>1.216100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=9156, training_loss=1.2555272346919881, metrics={'train_runtime': 10388.5692, 'train_samples_per_second': 14.102, 'train_steps_per_second': 0.881, 'total_flos': 3.968401947387494e+16, 'train_loss': 1.2555272346919881, 'epoch': 0.9999453939824169})"},"metadata":{}}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"m2m_mlm\", 'zip', \"/kaggle/working/m2m_smugri_finetuned/checkpoint-9156\")","metadata":{"execution":{"iopub.status.busy":"2024-09-07T16:51:50.282383Z","iopub.execute_input":"2024-09-07T16:51:50.283324Z","iopub.status.idle":"2024-09-07T16:57:43.383422Z","shell.execute_reply.started":"2024-09-07T16:51:50.283276Z","shell.execute_reply":"2024-09-07T16:57:43.382409Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/m2m_mlm.zip'"},"metadata":{}}]},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink('m2m_mlm.zip')","metadata":{"execution":{"iopub.status.busy":"2024-09-07T16:57:43.385656Z","iopub.execute_input":"2024-09-07T16:57:43.386591Z","iopub.status.idle":"2024-09-07T16:57:43.393787Z","shell.execute_reply.started":"2024-09-07T16:57:43.386526Z","shell.execute_reply":"2024-09-07T16:57:43.392687Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/m2m_mlm.zip","text/html":"<a href='m2m_mlm.zip' target='_blank'>m2m_mlm.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}